{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ha8gdxiDalz"
      },
      "source": [
        "## **Aim:- Blur the specific  object present in the video**\n",
        "### **Author: Shalu Singh**\n",
        "### **Date: 12/09/23**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4RC-rgxDT_D",
        "outputId": "49d14436-8fb6-4ee6-e5c2-5c77d1ba808b"
      },
      "outputs": [],
      "source": [
        "# # mount google drive\n",
        "# from google.colab import drive\n",
        "# # dr jnbive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nkOphULwD8s7"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IfZGu9r0EnWw"
      },
      "outputs": [],
      "source": [
        "# function: blur the image\n",
        "def blur_image(image,coordinates = None):\n",
        "  img = image.copy() # copy the image to work on new image\n",
        "  if (coordinates is not None):\n",
        "    #print('Performing image blur operation...')\n",
        "    for coord in (coordinates):\n",
        "      ymin,xmin,ymax,xmax = coord\n",
        "      #print('Image shape:',img.shape)\n",
        "      # Extract region of intrest\n",
        "      Y_min,X_min,Y_max,X_max = int(ymin*img.shape[0]),int(xmin*img.shape[1]),int(ymax*img.shape[0]),int(xmax*img.shape[1])\n",
        "      #print('Y_min,Y_max',Y_min,Y_max)\n",
        "      #print('X_min,X_max',X_min,X_max)\n",
        "      roi = img[Y_min:Y_max,X_min:X_max]\n",
        "      #show_img(roi,'Original_roi')\n",
        "      # blur the extracted img using Gausian blur\n",
        "      try:\n",
        "        roi = cv2.GaussianBlur(roi,(7,7),5)\n",
        "        #show_img(roi,title='blured roi')\n",
        "        # replace the original roi with blured_roi\n",
        "        img[Y_min:Y_max, X_min:X_max] = roi\n",
        "\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "78hJLFz2YO47"
      },
      "outputs": [],
      "source": [
        "# function: get image info.\n",
        "def get_info(img):\n",
        "  print('Image shape:',img.shape)\n",
        "  print('Image Dtype:',img.dtype)\n",
        "  print('Image Min. Value:',tf.reduce_min(img))\n",
        "  print('Image Max. Value:',tf.reduce_max(img))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9pTFvIuFH_CJ"
      },
      "outputs": [],
      "source": [
        "# function: to show the image\n",
        "def show_img(img,title = ''):\n",
        "  try:\n",
        "    img = img.astype('uint8')\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "  except:\n",
        "    print('IMAGE NOT SHOWN!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pO8AaoyAfaDw"
      },
      "outputs": [],
      "source": [
        "# detector_boxes = detector_output['detection_boxes']\n",
        "# det_score = detector_output['detection_scores']\n",
        "# sel_boxes = detector_boxes[det_score > 0.5].numpy()\n",
        "# ymin,xmin,ymax,xmax = sel_boxes[0]\n",
        "# print(ymin,xmin,ymax,xmax)\n",
        "# ymin,xmin,ymax,xmax = int(ymin*original_img.shape[1]),int(xmin*original_img.shape[2]),int(ymax*original_img.shape[1]),int(xmax*original_img.shape[2])\n",
        "# print(ymin,xmin,ymax,xmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T5sU4fenj9i4"
      },
      "outputs": [],
      "source": [
        "# k = original_img[0]\n",
        "# k = k[ymin:ymax,xmin:xmax]\n",
        "# show_img(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xZvCrHCdeSu2"
      },
      "outputs": [],
      "source": [
        "# function: filter detection boxs\n",
        "def filter_detection(detector_output,thr = 0.5):\n",
        "  detection_boxs = detector_output['detection_boxes']\n",
        "  detection_class = detector_output['detection_classes']\n",
        "  detection_scores = detector_output['detection_scores']\n",
        "\n",
        "  # filter the detection boxses based on threshold\n",
        "  selected_scores = detection_scores[detection_scores >= thr]\n",
        "  selected_class = detection_class[detection_scores >= thr]\n",
        "  selected_boxs = detection_boxs[detection_scores >= thr].numpy()\n",
        "\n",
        "  return selected_boxs,selected_class,selected_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "tAAiAaCNcULL",
        "outputId": "d4139cd6-e5b3-4c27-c843-4cb666e977e7"
      },
      "outputs": [],
      "source": [
        "# function: to get info. of detection output\n",
        "def detection_info(detector_output):\n",
        "  print('Number of detection:',detector_output['num_detections'][0].numpy())\n",
        "  print(\"Detection class label:\",detector_output['detection_classes'][0].numpy())\n",
        "  #print('Detection boxes coordinates:',detector_output['detection_boxes'])\n",
        "  print('Detection scores:',detector_output['detection_scores'][0].numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "onxe3XO0TdZ5"
      },
      "outputs": [],
      "source": [
        "# # function: draw bounding box in an image\n",
        "# def bounding_box(img,coordinates):\n",
        "#   # define the color of the bouding box\n",
        "#   color = (0,255,0) # (BGR)\n",
        "#     # box thickness\n",
        "#   thickness = 2\n",
        "#   #  convert coordinates to integer\n",
        "#   for i in coordinates:\n",
        "#     y_min,x_min,y_max,x_max = i.astype('uint8')\n",
        "\n",
        "#     # Drawing the bounding box on the image\n",
        "#     img = cv2.rectangle(img,(x_min,y_min),(x_max,y_max),color,thickness)\n",
        "#   # show the image\n",
        "#   print('Bounding box image')\n",
        "#   show_img(img)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6QQXICbTIOpH"
      },
      "outputs": [],
      "source": [
        "# # function to load the form local disk\n",
        "# def load_img(img_path):\n",
        "#   # check if image path exist or not\n",
        "#   if not(os.path.exists(img_path)):\n",
        "#     print(\"Img not found!\")\n",
        "#     return None\n",
        "#   else:\n",
        "#     print('Img found')\n",
        "#     img = Image.open(img_path)\n",
        "#     print('Image loaded successfully!')\n",
        "#     # convert the image to tensor\n",
        "#     img = tf.convert_to_tensor(img)\n",
        "#     # resize the image to shape: 520,520,chanel\n",
        "#     img = tf.image.resize(img,(520,520))\n",
        "#     # get img info\n",
        "#     get_info(img)\n",
        "#     # add additional dimension to image\n",
        "#     # new shape: batch,height,width,chanel\n",
        "#     img = tf.expand_dims(img,axis = 0) # add unit batch size\n",
        "#     # convert to numpy\n",
        "#     # get new img info\n",
        "#     get_info(img)\n",
        "#     img = np.asarray(img)\n",
        "#     return img\n",
        "#     # except:\n",
        "#     #   print('Failed to load image')\n",
        "#     #   return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLkhVYK9JK32",
        "outputId": "c37794d9-b18c-42c0-9070-81e6d1cc6b27"
      },
      "outputs": [],
      "source": [
        "# # testing the load img function\n",
        "# img_path = '/content/drive/MyDrive/Dataset/ped_corss.jpg'\n",
        "# original_img = load_img(img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "vV04s2jPLudx",
        "outputId": "378a5db7-12da-4fe0-ce2a-27af6dde48e9"
      },
      "outputs": [],
      "source": [
        "# show_img(original_img[0],'Original Image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTYYsIuPMYk_"
      },
      "source": [
        "##### Load the object detection model: **ssd_mobilenet_v2**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ygznnYbZL6qT"
      },
      "outputs": [],
      "source": [
        "# #model_path =  'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\n",
        "object_detection_model = tf.saved_model.load('mobilenet_model/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "pxCEiJRIMtct"
      },
      "outputs": [],
      "source": [
        "# # test loaded model\n",
        "# detector_output = object_detection_model(original_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "dgKnMLsIqoTb"
      },
      "outputs": [],
      "source": [
        "# # get filtered detection output\n",
        "# boxes,classes,scores = filter_detection(detector_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1N_-CH6OJbx",
        "outputId": "9bf33b63-71aa-4820-9850-aed745e5f7ae"
      },
      "outputs": [],
      "source": [
        "# # blur the image\n",
        "# output_img = blur_image(original_img,boxes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3V8lfHpsDVL",
        "outputId": "55e029ca-eadd-4de6-c90c-db1027132400"
      },
      "outputs": [],
      "source": [
        "# get_info(output_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "zCfuoByCO0HK",
        "outputId": "447d7538-a8aa-4032-fb22-5c82fc3e25fb"
      },
      "outputs": [],
      "source": [
        "# # resulted image\n",
        "# show_img(output_img,title = 'Output Image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I5faCv9v0e1"
      },
      "source": [
        "### Image capturing and bluring image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "oux9evfOQ7B5"
      },
      "outputs": [],
      "source": [
        "# import opencv\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9AyzFY1wAmm",
        "outputId": "9b692b4f-9f77-4cb2-acad-05204465ae0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# load video from local disk\n",
        "ip_video_path = 'Hit_Video.mp4'\n",
        "# laod the video\n",
        "try:\n",
        "  cap = cv2.VideoCapture(ip_video_path)\n",
        "  print('Video loaded successfully!')\n",
        "except:\n",
        "  print(\"Failed! to load video\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "_mm-tdMGxKe8"
      },
      "outputs": [],
      "source": [
        "# get video property like frame_width,frame_heigh,frame_per_second(fps),codecc\n",
        "frame_width = int(cap.get(3)) # width of the fames in the video\n",
        "frame_height = int(cap.get(4)) # height of the frame in the video\n",
        "fps = int(cap.get(5)) # frame per second\n",
        "codecc = cv2.VideoWriter_fourcc(*'XVID') # codecc for output video (XVID default codecc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6SvWewwxLg8",
        "outputId": "7ebcae30-169b-4701-d0e2-97c6f435924c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frame Width: 640\n",
            "Frame height: 360\n",
            "Frame Per Second: 30\n"
          ]
        }
      ],
      "source": [
        "print('Frame Width:',frame_width)\n",
        "print('Frame height:',frame_height)\n",
        "print('Frame Per Second:',fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "aoE9Lk01xNyK"
      },
      "outputs": [],
      "source": [
        "# VideoWriter object to save blured video\n",
        "op_video_path = 'output_blured_video.mp4'\n",
        "out = cv2.VideoWriter(op_video_path,codecc,fps,(frame_width,frame_height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5yBDVFfnxy1k",
        "outputId": "0847b5b5-8b37-4bd3-8735-a6cfe18721b8"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32md:\\Placements_Projects\\P_02_Image_Blur\\Project_02_Image_blur.ipynb Cell 28\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Placements_Projects/P_02_Image_Blur/Project_02_Image_blur.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread() \u001b[39m# Read frame from the input image\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Placements_Projects/P_02_Image_Blur/Project_02_Image_blur.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#print('Original frame shape:',frame.shape)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Placements_Projects/P_02_Image_Blur/Project_02_Image_blur.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#print('fame shape:',frame.shape)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Placements_Projects/P_02_Image_Blur/Project_02_Image_blur.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Expand frame dimension\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Placements_Projects/P_02_Image_Blur/Project_02_Image_blur.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m frame \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(frame,axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Placements_Projects/P_02_Image_Blur/Project_02_Image_blur.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ret:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Placements_Projects/P_02_Image_Blur/Project_02_Image_blur.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   \u001b[39mbreak\u001b[39;00m \u001b[39m# break if we have reached the end of the video\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\sinte\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\sinte\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m     97\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39mEagerTensor(value, ctx\u001b[39m.\u001b[39mdevice_name, dtype)\n",
            "\u001b[1;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
          ]
        }
      ],
      "source": [
        "# Loop through each video frame,blured the image and write in output video\n",
        "while True:\n",
        "  ret, frame = cap.read() # Read frame from the input image\n",
        "  #print('Original frame shape:',frame.shape)\n",
        "  #print('fame shape:',frame.shape)\n",
        "  # Expand frame dimension\n",
        "  if ret:\n",
        "    frame = tf.expand_dims(frame,axis = 0)\n",
        "  else:\n",
        "    break # break if we have reached the end of the video\n",
        "  # Blur the image\n",
        "  detector_output = object_detection_model(frame)\n",
        "  boxes,classes,scores = filter_detection(detector_output)\n",
        "\n",
        "  #print('New frame shape:',frame[0].shape)\n",
        "  blured_img = blur_image(frame[0].numpy(),boxes)\n",
        "  #print('blured_img_shape',blured_img.shape)\n",
        "  # write blured frame to output image\n",
        "  out.write(blured_img)\n",
        "  # Display original and blured frame\n",
        "  #show_img(frame[0].numpy(),'Original_frame')\n",
        "  #show_img(blured_img,'Blured_frame')\n",
        "\n",
        "\n",
        "  #break the loop if key 'q' is pressed\n",
        "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "    break\n",
        "\n",
        "\n",
        "# realease video capture and writer object\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# close all opencv windows\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ruMyh854lU-"
      },
      "outputs": [],
      "source": [
        "  for i in n_coordin:\n",
        "    y_min,x_min,y_max,x_max = i.astype('uint8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL8msj154x0W",
        "outputId": "c8e376c8-ff72-4c89-f4db-3ca78ecd12c1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgQCU99j4z3-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
